# Using voice processing

**Framework**: AVFAudio

Add voice-processing capabilities to your app by using audio engine.

**Availability**:
- iOS 17.0+
- iPadOS 17.0+
- Xcode 15.4+

#### Overview

> **Note**: This sample code project is associated with WWDC 2019 session [`510: What’s New in AVAudioEngine`](https://developer.apple.comhttps://developer.apple.com/videos/play/wwdc19/510/).

This sample code project is associated with WWDC 2019 session [`510: What’s New in AVAudioEngine`](https://developer.apple.comhttps://developer.apple.com/videos/play/wwdc19/510/).

##### Configure the Sample Code Project

Before you run the sample code project in Xcode, ensure you’re using iOS 17 or later.

## See Also

- [Playing custom audio with your own player](playing-custom-audio-with-your-own-player.md)
  Construct an audio player to play your custom audio data, and optionally take advantage of the advanced features of AirPlay 2.
- [class AVAudioPlayerNode](avaudioplayernode.md)
  An object for scheduling the playback of buffers or segments of audio files.


---

*[View on Apple Developer](https://developer.apple.com/documentation/avfaudio/using-voice-processing)*