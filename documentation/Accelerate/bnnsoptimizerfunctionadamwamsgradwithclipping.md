# BNNSOptimizerFunctionAdamWAMSGradWithClipping

**Framework**: Accelerate  
**Kind**: var

An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm and optionally clips the gradient by value or by norm.

**Availability**:
- iOS 15.0+
- iPadOS 15.0+
- Mac Catalyst 15.0+
- macOS 12.0+
- tvOS 15.0+
- visionOS 1.0+
- watchOS 8.0+

## Declaration

```swift
var BNNSOptimizerFunctionAdamWAMSGradWithClipping: BNNSOptimizerFunction { get }
```

## See Also

- [var BNNSOptimizerFunctionAdamW: BNNSOptimizerFunction](bnnsoptimizerfunctionadamw.md)
  An optimizer function that updates parameters according to the AdamW algorithm.
- [var BNNSOptimizerFunctionAdamWWithClipping: BNNSOptimizerFunction](bnnsoptimizerfunctionadamwwithclipping.md)
  An optimizer function that updates parameters according to the AdamW algorithm and optionally clips the gradient by value or by norm.
- [var BNNSOptimizerFunctionAdamWAMSGrad: BNNSOptimizerFunction](bnnsoptimizerfunctionadamwamsgrad.md)
  An optimizer function that updates parameters according to the AMSGrad variant of the AdamW algorithm.


---

*[View on Apple Developer](https://developer.apple.com/documentation/accelerate/bnnsoptimizerfunctionadamwamsgradwithclipping)*